{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "\n",
    "from deeppavlov.core.commands.train import read_data_by_config, train_evaluate_model_from_config\n",
    "from deeppavlov.core.commands.infer import interact_model, build_model\n",
    "from deeppavlov.core.commands.utils import expand_path, parse_config\n",
    "from deeppavlov.core.common.params import from_params\n",
    "from deeppavlov.core.common.errors import ConfigError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read unlabelled data for label propagation\n",
    "def read_unlabelled_data(UNLABELLED_DATA_PATH):\n",
    "    with open(UNLABELLED_DATA_PATH, \"r\") as f:\n",
    "        unlabelled_data = f.read().splitlines()\n",
    "    unlabelled_data = [x for x in unlabelled_data if x != '']\n",
    "    return unlabelled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_pl_config(CONFIG_PATH):\n",
    "    config_path_pl = Path(CONFIG_PATH).parent / Path(Path(CONFIG_PATH).stem + \"_pl.json\")\n",
    "\n",
    "    with open(CONFIG_PATH, \"r\") as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    config_pl = deepcopy(config)\n",
    "    config_pl[\"dataset_reader\"][\"train\"] = Path(config_pl[\"dataset_reader\"].get(\"train\", \"train.csv\")).stem + \"_pl.csv\"\n",
    "    \n",
    "    with open(config_path_pl, \"w\") as f:\n",
    "        json.dump(config_pl, f, indent=2)\n",
    "    \n",
    "    return config, config_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_extended_data(config, samples, labels, new_config = None):\n",
    "    train_data = read_data_by_config(deepcopy(config))\n",
    "    \n",
    "    for i in range(len(samples)):\n",
    "        train_data[\"train\"].append((samples[i], labels[i]))\n",
    "    df = pd.DataFrame(train_data[\"train\"], \n",
    "                      columns=[config[\"dataset_reader\"][\"x\"], \n",
    "                               config[\"dataset_reader\"][\"y\"]])\n",
    "    df[config[\"dataset_reader\"][\"y\"]] = df[config[\"dataset_reader\"][\"y\"]].apply(\n",
    "        lambda x: config[\"dataset_reader\"].get(\"class_sep\", \",\").join(x))\n",
    "    \n",
    "    if new_config is not None:\n",
    "        config = new_config\n",
    "    file = expand_path(Path(config[\"dataset_reader\"][\"data_path\"]) / \n",
    "                       Path(config[\"dataset_reader\"][\"train\"]))\n",
    "\n",
    "    if config[\"dataset_reader\"].get(\"format\", \"csv\") == \"csv\":\n",
    "        keys = ('sep', 'header', 'names')\n",
    "        df.to_csv(file, \n",
    "                  index=False,\n",
    "                  sep=config[\"dataset_reader\"].get(\"sep\", \",\")\n",
    "                 )\n",
    "    elif config[\"dataset_reader\"].get(\"format\", \"csv\") == \"json\":\n",
    "        keys = ('orient', 'lines')\n",
    "        df.to_json(file, \n",
    "                  index=False,\n",
    "                  orient=config[\"dataset_reader\"].get(\"orient\", None),\n",
    "                  lines=config[\"dataset_reader\"].get(\"lines\", False)\n",
    "                  )\n",
    "    else:\n",
    "        raise ConfigError(\"Can not work with current data format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_reader': {'class_name': 'basic_classification_reader',\n",
       "  'x': 'Title',\n",
       "  'y': 'Label',\n",
       "  'data_path': '~/.deeppavlov/downloads/convers_vs_info_data/',\n",
       "  'train': 'train_sber.csv',\n",
       "  'valid': 'valid_sber.csv'},\n",
       " 'dataset_iterator': {'class_name': 'basic_classification_iterator',\n",
       "  'seed': 42},\n",
       " 'chainer': {'in': ['x'],\n",
       "  'in_y': ['y'],\n",
       "  'pipe': [{'id': 'classes_vocab',\n",
       "    'class_name': 'simple_vocab',\n",
       "    'fit_on': ['y'],\n",
       "    'save_path': '~/.deeppavlov/models/classifiers/convers_vs_info/model_v0/classes.dict',\n",
       "    'load_path': '~/.deeppavlov/models/classifiers/convers_vs_info/model_v0/classes.dict',\n",
       "    'in': 'y',\n",
       "    'out': 'y_ids'},\n",
       "   {'in': ['x'],\n",
       "    'out': ['x_prep'],\n",
       "    'class_name': 'dirty_comments_preprocessor',\n",
       "    'remove_punctuation': False},\n",
       "   {'in': 'x_prep',\n",
       "    'out': 'x_tok',\n",
       "    'id': 'my_tokenizer',\n",
       "    'class_name': 'nltk_moses_tokenizer'},\n",
       "   {'in': ['x_tok'],\n",
       "    'out': ['x_emb'],\n",
       "    'id': 'my_embedder',\n",
       "    'class_name': 'elmo',\n",
       "    'elmo_output_names': ['elmo'],\n",
       "    'mini_batch_size': 8,\n",
       "    'spec': '~/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/'},\n",
       "   {'in': 'y_ids',\n",
       "    'out': 'y_onehot',\n",
       "    'class_name': 'one_hotter',\n",
       "    'id': 'my_one_hotter',\n",
       "    'depth': '#classes_vocab.len'},\n",
       "   {'in': ['x_emb'],\n",
       "    'in_y': ['y_onehot'],\n",
       "    'out': ['y_pred_probas'],\n",
       "    'main': True,\n",
       "    'class_name': 'keras_classification_model',\n",
       "    'save_path': '~/.deeppavlov/models/classifiers/convers_vs_info/model_v0/model',\n",
       "    'load_path': '~/.deeppavlov/models/classifiers/convers_vs_info/model_v0/model',\n",
       "    'embedding_size': '#my_embedder.dim',\n",
       "    'n_classes': '#classes_vocab.len',\n",
       "    'units_gru': 256,\n",
       "    'optimizer': 'Adam',\n",
       "    'lear_rate': 0.001,\n",
       "    'lear_rate_decay': 0.001,\n",
       "    'loss': 'categorical_crossentropy',\n",
       "    'text_size': 20,\n",
       "    'coef_reg_gru': 1e-05,\n",
       "    'coef_reg_den': 1e-05,\n",
       "    'dropout_rate': 0.5,\n",
       "    'rec_dropout_rate': 0.5,\n",
       "    'dense_size': 100,\n",
       "    'model_name': 'bigru_with_max_aver_pool_model',\n",
       "    'last_layer_activation': 'softmax',\n",
       "    'restore_lr': False},\n",
       "   {'in': 'y_pred_probas',\n",
       "    'out': 'y_pred_ids',\n",
       "    'class_name': 'proba2labels',\n",
       "    'max_proba': True},\n",
       "   {'in': 'y_pred_ids', 'out': 'y_pred_labels', 'ref': 'classes_vocab'},\n",
       "   {'ref': 'my_one_hotter', 'in': 'y_pred_ids', 'out': 'y_pred_onehot'}],\n",
       "  'out': ['y_pred_probas']},\n",
       " 'train': {'epochs': 20,\n",
       "  'batch_size': 256,\n",
       "  'metrics': [{'name': 'roc_auc', 'inputs': ['y_onehot', 'y_pred_probas']},\n",
       "   {'name': 'sets_accuracy', 'inputs': ['y', 'y_pred_labels']},\n",
       "   {'name': 'f1_macro', 'inputs': ['y', 'y_pred_labels']}],\n",
       "  'validation_patience': 5,\n",
       "  'val_every_n_epochs': 1,\n",
       "  'log_every_n_epochs': 1,\n",
       "  'show_examples': False,\n",
       "  'validate_best': True,\n",
       "  'test_best': False,\n",
       "  'tensorboard_log_dir': '~/.deeppavlov/models/classifiers/convers_vs_info/model_v0/'},\n",
       " 'metadata': {'variables': {'ROOT_PATH': '~/.deeppavlov',\n",
       "   'DOWNLOADS_PATH': '~/.deeppavlov/downloads',\n",
       "   'MODELS_PATH': '~/.deeppavlov/models'},\n",
       "  'requirements': ['../dp_requirements/tf.txt',\n",
       "   '../dp_requirements/fasttext.txt'],\n",
       "  'labels': {'telegram_utils': 'IntentModel',\n",
       "   'server_utils': 'KerasIntentModel'},\n",
       "  'download': [{'url': 'http://files.deeppavlov.ai/embeddings/yahooo-sber-questions_epoches_n_9.tar.gz',\n",
       "    'subdir': '~/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/'},\n",
       "   {'url': 'http://files.deeppavlov.ai/datasets/convers_vs_info_data.tar.gz',\n",
       "    'subdir': '~/.deeppavlov/downloads/'}]}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually given parameters for pseudo-labeling\n",
    "\n",
    "# path to config file\n",
    "CONFIG_PATH = \"../deeppavlov/configs/classifiers/convers_vs_info.json\"\n",
    "# read config, compose new one, save it\n",
    "config, config_pl = make_pl_config(CONFIG_PATH)\n",
    "config, config_pl = parse_config(config), parse_config(config_pl)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to file with unlabelled data\n",
    "UNLABELLED_DATA_PATH = expand_path(Path(config[\"dataset_reader\"][\"data_path\"])) / Path(\"question_L6.txt\")\n",
    "# number of samples that are going to be labelled during one iteration of label propagation\n",
    "ONE_ITERATION_PORTION = 2000\n",
    "# number of iterations\n",
    "N_ITERATIONS = 10\n",
    "CLASSES_VOCAB_ID_IN_PIPE = 0\n",
    "CONFIDENT_PROBA = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-19 14:27:35.33 WARNING in 'deeppavlov.dataset_readers.basic_classification_reader'['basic_classification_reader'] at line 97: Cannot find /home/dilyara/.deeppavlov/downloads/convers_vs_info_data/test.csv file\n"
     ]
    }
   ],
   "source": [
    "# read unlabelled dataset\n",
    "unlabelled_data = read_unlabelled_data(UNLABELLED_DATA_PATH)\n",
    "\n",
    "# save initial dataset as extended\n",
    "save_extended_data(config, [], [], new_config=config_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-19 14:27:35.138 WARNING in 'deeppavlov.dataset_readers.basic_classification_reader'['basic_classification_reader'] at line 97: Cannot find /home/dilyara/.deeppavlov/downloads/convers_vs_info_data/test.csv file\n",
      "2018-11-19 14:27:35.275 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 89: [saving vocabulary to /home/dilyara/.deeppavlov/models/classifiers/convers_vs_info/model_v0/classes.dict]\n",
      "[nltk_data] Downloading package punkt to /home/dilyara/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/dilyara/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /home/dilyara/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /home/dilyara/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n",
      "Using TensorFlow backend.\n",
      "2018-11-19 14:27:36.456 INFO in 'tensorflow'['tf_logging'] at line 159: Using /tmp/tfhub_modules to cache modules.\n",
      "2018-11-19 14:27:38.106 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/aggregation/elmo_output_ELMo_W:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with aggregation/elmo_output_ELMo_W\n",
      "2018-11-19 14:27:38.109 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/aggregation/elmo_output_ELMo_gamma:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with aggregation/elmo_output_ELMo_gamma\n",
      "2018-11-19 14:27:38.112 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/CNN/W_cnn_0:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/CNN/W_cnn_0\n",
      "2018-11-19 14:27:38.114 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/CNN/W_cnn_1:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/CNN/W_cnn_1\n",
      "2018-11-19 14:27:38.117 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/CNN/W_cnn_2:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/CNN/W_cnn_2\n",
      "2018-11-19 14:27:38.120 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/CNN/W_cnn_3:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/CNN/W_cnn_3\n",
      "2018-11-19 14:27:38.123 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/CNN/W_cnn_4:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/CNN/W_cnn_4\n",
      "2018-11-19 14:27:38.128 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/CNN/W_cnn_5:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/CNN/W_cnn_5\n",
      "2018-11-19 14:27:38.132 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/CNN/W_cnn_6:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/CNN/W_cnn_6\n",
      "2018-11-19 14:27:38.136 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/CNN/b_cnn_0:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/CNN/b_cnn_0\n",
      "2018-11-19 14:27:38.140 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/CNN/b_cnn_1:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/CNN/b_cnn_1\n",
      "2018-11-19 14:27:38.144 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/CNN/b_cnn_2:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/CNN/b_cnn_2\n",
      "2018-11-19 14:27:38.147 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/CNN/b_cnn_3:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/CNN/b_cnn_3\n",
      "2018-11-19 14:27:38.153 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/CNN/b_cnn_4:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/CNN/b_cnn_4\n",
      "2018-11-19 14:27:38.156 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/CNN/b_cnn_5:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/CNN/b_cnn_5\n",
      "2018-11-19 14:27:38.162 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/CNN/b_cnn_6:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/CNN/b_cnn_6\n",
      "2018-11-19 14:27:38.167 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/CNN_high_0/W_carry:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/CNN_high_0/W_carry\n",
      "2018-11-19 14:27:38.172 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/CNN_high_0/W_transform:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/CNN_high_0/W_transform\n",
      "2018-11-19 14:27:38.178 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/CNN_high_0/b_carry:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/CNN_high_0/b_carry\n",
      "2018-11-19 14:27:38.181 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/CNN_high_0/b_transform:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/CNN_high_0/b_transform\n",
      "2018-11-19 14:27:38.183 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/CNN_high_1/W_carry:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/CNN_high_1/W_carry\n",
      "2018-11-19 14:27:38.186 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/CNN_high_1/W_transform:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/CNN_high_1/W_transform\n",
      "2018-11-19 14:27:38.189 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/CNN_high_1/b_carry:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/CNN_high_1/b_carry\n",
      "2018-11-19 14:27:38.194 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/CNN_high_1/b_transform:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/CNN_high_1/b_transform\n",
      "2018-11-19 14:27:38.198 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/CNN_proj/W_proj:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/CNN_proj/W_proj\n",
      "2018-11-19 14:27:38.203 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/CNN_proj/b_proj:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/CNN_proj/b_proj\n",
      "2018-11-19 14:27:38.206 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-19 14:27:38.209 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel\n",
      "2018-11-19 14:27:38.211 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel\n",
      "2018-11-19 14:27:38.215 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias\n",
      "2018-11-19 14:27:38.218 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel\n",
      "2018-11-19 14:27:38.221 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel\n",
      "2018-11-19 14:27:38.224 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias\n",
      "2018-11-19 14:27:38.226 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel\n",
      "2018-11-19 14:27:38.229 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel\n",
      "2018-11-19 14:27:38.232 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias\n",
      "2018-11-19 14:27:38.234 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel\n",
      "2018-11-19 14:27:38.237 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel\n",
      "2018-11-19 14:27:38.240 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/Variable:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/Variable\n",
      "2018-11-19 14:27:38.245 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/Variable_1:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/Variable_1\n",
      "2018-11-19 14:27:38.248 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/Variable_2:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/Variable_2\n",
      "2018-11-19 14:27:38.253 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/Variable_3:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/Variable_3\n",
      "2018-11-19 14:27:38.257 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/Variable_4:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/Variable_4\n",
      "2018-11-19 14:27:38.260 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/Variable_5:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/Variable_5\n",
      "2018-11-19 14:27:38.263 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/Variable_6:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/Variable_6\n",
      "2018-11-19 14:27:38.266 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/Variable_7:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/Variable_7\n",
      "2018-11-19 14:27:38.269 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm/char_embed:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm/char_embed\n",
      "2018-11-19 14:27:38.272 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm_1/Variable:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm_1/Variable\n",
      "2018-11-19 14:27:38.275 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm_1/Variable_1:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm_1/Variable_1\n",
      "2018-11-19 14:27:38.278 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm_1/Variable_2:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm_1/Variable_2\n",
      "2018-11-19 14:27:38.281 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm_1/Variable_3:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm_1/Variable_3\n",
      "2018-11-19 14:27:38.284 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm_1/Variable_4:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm_1/Variable_4\n",
      "2018-11-19 14:27:38.287 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm_1/Variable_5:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm_1/Variable_5\n",
      "2018-11-19 14:27:38.290 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm_1/Variable_6:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm_1/Variable_6\n",
      "2018-11-19 14:27:38.293 DEBUG in 'tensorflow'['tf_logging'] at line 100: Initialize variable module/bilm_1/Variable_7:0 from checkpoint b'/home/dilyara/.deeppavlov/downloads/embeddings/yahooo-sber-questions_epoches_n_9/variables/variables' with bilm_1/Variable_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-19 14:27:39.735 INFO in 'tensorflow'['tf_logging'] at line 115: Saver not created because there are no variables in the graph to restore\n",
      "2018-11-19 14:27:40.130 INFO in 'deeppavlov.models.classifiers.keras_classification_model'['keras_classification_model'] at line 258: [initializing `KerasClassificationModel` from scratch as bigru_with_max_aver_pool_model]\n",
      "2018-11-19 14:27:40.800 INFO in 'deeppavlov.models.classifiers.keras_classification_model'['keras_classification_model'] at line 132: Model was successfully initialized!\n",
      "Model summary:\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 20, 1024)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 20, 1024)     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) [(None, 20, 512), (N 1967616     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 512)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 512)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1536)         0           global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_average_pooling1d_1[0][0] \n",
      "                                                                 bidirectional_1[0][1]            \n",
      "                                                                 bidirectional_1[0][2]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1536)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          153700      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 100)          0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            202         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 2)            0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,121,518\n",
      "Trainable params: 2,121,518\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "2018-11-19 14:27:43.534 INFO in 'deeppavlov.core.commands.train'['train'] at line 356: New best roc_auc of 0.3269\n",
      "2018-11-19 14:27:43.534 INFO in 'deeppavlov.core.commands.train'['train'] at line 358: Saving model\n",
      "2018-11-19 14:27:43.535 INFO in 'deeppavlov.models.classifiers.keras_classification_model'['keras_classification_model'] at line 372: [saving model to /home/dilyara/.deeppavlov/models/classifiers/convers_vs_info/model_v0/model_opt.json]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 181, \"metrics\": {\"roc_auc\": 0.3269, \"sets_accuracy\": 0.547, \"f1_macro\": 0.3644}, \"time_spent\": \"0:00:03\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 5}}\n",
      "{\"train\": {\"epochs_done\": 1, \"batches_seen\": 7, \"train_examples_seen\": 1619, \"metrics\": {\"roc_auc\": 0.5243, \"sets_accuracy\": 0.53, \"f1_macro\": 0.5252}, \"time_spent\": \"0:00:32\", \"loss\": 1.1731205923216683}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dilyara/anaconda3/envs/deep36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "2018-11-19 14:28:14.363 INFO in 'deeppavlov.core.commands.train'['train'] at line 524: New best roc_auc of 0.7989\n",
      "2018-11-19 14:28:14.365 INFO in 'deeppavlov.core.commands.train'['train'] at line 526: Saving model\n",
      "2018-11-19 14:28:14.365 INFO in 'deeppavlov.models.classifiers.keras_classification_model'['keras_classification_model'] at line 372: [saving model to /home/dilyara/.deeppavlov/models/classifiers/convers_vs_info/model_v0/model_opt.json]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 181, \"metrics\": {\"roc_auc\": 0.7989, \"sets_accuracy\": 0.5525, \"f1_macro\": 0.3559}, \"time_spent\": \"0:00:34\", \"epochs_done\": 1, \"batches_seen\": 7, \"train_examples_seen\": 1619, \"impatience\": 0, \"patience_limit\": 5}}\n",
      "{\"train\": {\"epochs_done\": 2, \"batches_seen\": 14, \"train_examples_seen\": 3238, \"metrics\": {\"roc_auc\": 0.872, \"sets_accuracy\": 0.7573, \"f1_macro\": 0.7279}, \"time_spent\": \"0:01:01\", \"loss\": 0.6307094352585929}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-19 14:28:42.743 INFO in 'deeppavlov.core.commands.train'['train'] at line 524: New best roc_auc of 0.9525\n",
      "2018-11-19 14:28:42.744 INFO in 'deeppavlov.core.commands.train'['train'] at line 526: Saving model\n",
      "2018-11-19 14:28:42.745 INFO in 'deeppavlov.models.classifiers.keras_classification_model'['keras_classification_model'] at line 372: [saving model to /home/dilyara/.deeppavlov/models/classifiers/convers_vs_info/model_v0/model_opt.json]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 181, \"metrics\": {\"roc_auc\": 0.9525, \"sets_accuracy\": 0.884, \"f1_macro\": 0.8807}, \"time_spent\": \"0:01:02\", \"epochs_done\": 2, \"batches_seen\": 14, \"train_examples_seen\": 3238, \"impatience\": 0, \"patience_limit\": 5}}\n",
      "{\"train\": {\"epochs_done\": 3, \"batches_seen\": 21, \"train_examples_seen\": 4857, \"metrics\": {\"roc_auc\": 0.9548, \"sets_accuracy\": 0.903, \"f1_macro\": 0.9014}, \"time_spent\": \"0:01:28\", \"loss\": 0.4995504489966801}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-19 14:29:09.761 INFO in 'deeppavlov.core.commands.train'['train'] at line 524: New best roc_auc of 0.9641\n",
      "2018-11-19 14:29:09.761 INFO in 'deeppavlov.core.commands.train'['train'] at line 526: Saving model\n",
      "2018-11-19 14:29:09.762 INFO in 'deeppavlov.models.classifiers.keras_classification_model'['keras_classification_model'] at line 372: [saving model to /home/dilyara/.deeppavlov/models/classifiers/convers_vs_info/model_v0/model_opt.json]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 181, \"metrics\": {\"roc_auc\": 0.9641, \"sets_accuracy\": 0.9061, \"f1_macro\": 0.903}, \"time_spent\": \"0:01:29\", \"epochs_done\": 3, \"batches_seen\": 21, \"train_examples_seen\": 4857, \"impatience\": 0, \"patience_limit\": 5}}\n",
      "{\"train\": {\"epochs_done\": 4, \"batches_seen\": 28, \"train_examples_seen\": 6476, \"metrics\": {\"roc_auc\": 0.9655, \"sets_accuracy\": 0.9067, \"f1_macro\": 0.9053}, \"time_spent\": \"0:01:55\", \"loss\": 0.424065819808415}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-19 14:29:36.969 INFO in 'deeppavlov.core.commands.train'['train'] at line 524: New best roc_auc of 0.9681\n",
      "2018-11-19 14:29:36.970 INFO in 'deeppavlov.core.commands.train'['train'] at line 526: Saving model\n",
      "2018-11-19 14:29:36.971 INFO in 'deeppavlov.models.classifiers.keras_classification_model'['keras_classification_model'] at line 372: [saving model to /home/dilyara/.deeppavlov/models/classifiers/convers_vs_info/model_v0/model_opt.json]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 181, \"metrics\": {\"roc_auc\": 0.9681, \"sets_accuracy\": 0.9116, \"f1_macro\": 0.9099}, \"time_spent\": \"0:01:57\", \"epochs_done\": 4, \"batches_seen\": 28, \"train_examples_seen\": 6476, \"impatience\": 0, \"patience_limit\": 5}}\n",
      "{\"train\": {\"epochs_done\": 5, \"batches_seen\": 35, \"train_examples_seen\": 8095, \"metrics\": {\"roc_auc\": 0.974, \"sets_accuracy\": 0.9191, \"f1_macro\": 0.9183}, \"time_spent\": \"0:02:26\", \"loss\": 0.3873091084616525}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-19 14:30:07.915 INFO in 'deeppavlov.core.commands.train'['train'] at line 531: Did not improve on the roc_auc of 0.9681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 181, \"metrics\": {\"roc_auc\": 0.9638, \"sets_accuracy\": 0.9061, \"f1_macro\": 0.9044}, \"time_spent\": \"0:02:28\", \"epochs_done\": 5, \"batches_seen\": 35, \"train_examples_seen\": 8095, \"impatience\": 1, \"patience_limit\": 5}}\n"
     ]
    }
   ],
   "source": [
    "# first of all train initial model on the initial dataset (w/o pseudo-labeling)\n",
    "train_evaluate_model_from_config(deepcopy(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "available_unlabelled_ids = np.arange(len(unlabelled_data))\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "for i in range(N_ITERATIONS):\n",
    "    samples = []\n",
    "    labels = []\n",
    "    \n",
    "    ids_to_label = available_unlabelled_ids[\n",
    "        np.random.randint(low=0, \n",
    "                          high=len(available_unlabelled_ids), \n",
    "                          size=ONE_ITERATION_PORTION)]\n",
    "    available_unlabelled_ids = np.delete(available_unlabelled_ids, ids_to_label)\n",
    "    train_evaluate_model_from_config(deepcopy(config_pl))\n",
    "    model = build_model_from_config(deepcopy(config_pl))\n",
    "    classes = np.array(list(from_params(\n",
    "        deepcopy(config_pl[\"chainer\"][\"pipe\"][CLASSES_VOCAB_ID_IN_PIPE])).keys()))\n",
    "\n",
    "    for j, sample_id in enumerate(ids_to_label):\n",
    "        prediction = model([unlabelled_data[sample_id]])[0]\n",
    "        if len(np.where(np.array(prediction) > CONFIDENT_PROBA)[0]):\n",
    "            samples.append(unlabelled_data[sample_id])\n",
    "            labels.append(classes[np.where(np.array(prediction) > CONFIDENT_PROBA)])\n",
    "    \n",
    "    print(\"Iteration {}: add {} samples to train dataset\".format(i, len(samples)))\n",
    "    save_extended_data(config_pl, samples, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep36",
   "language": "python",
   "name": "deep36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
